The working of the code is as following:

in Symmetric.cpp,

the declaration at line number 405, 

   MatrixXd operator *(SymMat<_Scalar> const &m1,Eigen::MatrixXd &m){

    /*The try catch blocks */
    /*The try catch blocks */
    /*The try catch blocks */
    ll length = m1._Rows;
    MatrixXd result(length,length);                       //line number 453
    // Create an array of threads
    std::thread threads[THREADS_NUMBER];
    for (int i = 0; i < THREADS_NUMBER; ++i) {
      // Initialize each thread with the function responsible of multiplying only a part of the matrices
      threads[i] = std::thread(&multiply_threading<_Scalar>, std::ref(result), i, std::ref(m1), std::ref(m));
    }
    for (int i = 0; i < THREADS_NUMBER; ++i) {
      // Wait until each thead has finished
      threads[i].join();
    }
    return  result;
   }


First of all, the resultant array(MatrixXd result) is being declared which would store the result of the multiplication.
Then an array of threads is being created, where "THREADS_NUMBER" is a global variable declared at the beginning.
Currently, THREADS_NUMBER = 4, i.e 4 threads are being used. This number can be changed depending on the number of processors
of the system.

 Then each thread is initialized  giving it the function(declared at line number 363) to execute ** multiply_threading ** 
 that has the following form:

 void multiply_threading(Eigen::MatrixXd &result, const int thread_number,SymMat<_Scalar> const &m1,Eigen::MatrixXd &m2) 

  Here, the first parameter is output matrix, The second parameter is the thread number( explained later).The third and the
  fourth parameter are the matrices to be multiplied (The first one being Symmetric and the second one Eigen).

  When initializing a thread with a function like the above one, all parameters, by default, are passed by value,
  But I am passing them by reference.This is done automatically to prevent threads of writing the same memory address.
  This is to save time copying huge matrices.For this , std::ref(parameter) is used:

  threads[i] = std::thread(multiply_threading, std::ref(r), i, std::ref(m1), std::ref(m2));

  As the parameters are passed by reference a huge time is saved by again copying of matrices.




  Now, To avoid threads sharing the same data, an algorithm has been used such that each thread works on a particular and unique memory area. This is done in the function multiply_threading(). Skip to explanation part below.


   void multiply_threading(Eigen::MatrixXd &result, const int thread_number,SymMat<_Scalar> const &m1,Eigen::MatrixXd &m2) {
  // Calculate workload
  int MATRIX_SIZE = m1._Rows;
  const int n_elements = (MATRIX_SIZE * MATRIX_SIZE);
  const int n_operations = n_elements / THREADS_NUMBER;
  const int rest_operations = n_elements % THREADS_NUMBER;
  int start_op, end_op;
  ll length = m1._Rows;
  if (thread_number == 0) {
    // First thread does more job
    start_op = n_operations * thread_number;
    end_op = (n_operations * (thread_number + 1)) + rest_operations;
  }
  else {
    start_op = n_operations * thread_number + rest_operations;
    end_op = (n_operations * (thread_number + 1)) + rest_operations;
  }

  for (int op = start_op; op < end_op; ++op) {
    const int row = op % MATRIX_SIZE;
    const int col = op / MATRIX_SIZE;
    double r =0;
    for (int i = 0; i < MATRIX_SIZE; ++i) {
       double e1;
      double e2 = m2(i,col);
      
      if (row <= i)
      e1 = m1.symmatrix[(row * length - (row - 1) * row / 2 + i - row)];
      else
      e1 = m1.symmatrix[(i * length - (i - 1) * i / 2 + row - i)];
      r += e1 * e2;
    }

    result(row,col) = r;
  }
}



A matrix can be visualized as one dimensional array :
example :

matrix B = 
0 1 2 
3 4 5 
6 7 8

can be visualized as a 1D array = 0 1 2 3 4 5 6 7 8

Now with the help of this one dimensional visualization, the work of different threads can be split, like this:

    // Number of elements of the matrix (= size of the one-dimensional array)
    const int n_elements = (MATRIX_SIZE * MATRIX_SIZE);
    // Number of operations that each specific thread has to do
    const int n_operations = n_elements / THREADS_NUMBER;
    // Number of operations that are left and has to be done by other threads
    const int rest_operations = n_elements % THREADS_NUMBER;

It is just calculating the workload of each thread. This workload is given by the total number of operations divided by the number of workers (threads) that were initialized. Because this division may have a remainder, It has been taken into account.

Now, amount of work that each thread has to do is known and also the "extra work" (rest_operations).
 Now,it is to be decided in which part of the matrix this work has to be done, avoiding overlapping (as said earlier).
 This is where the thread_number is going to be used. The idea is very simple. The first thread is going to do its amount of work starting at the beginning of the matrix. The second thread is going to do its work starting at the end of the work of the first thread and so on. In code looks even easier:

 int start_op = n_operations * thread_number;   // Inclusive
 int end_op = (n_operations * (thread_number + 1));  // Exclusive

Suppose that we have a 3x3 matrix and 3 threads:

Thread 0:
start_op = 3 * 0 = 0
end_op = 3 * (0 + 1) = 3;
Thread 1:
start_op = 3 * 1 = 3
end_op = 3 * (1 + 1) = 6;
Thread 2:
start_op = 3 * 2 = 6
end_op = 3 * (2 + 1) = 9;

Here all the three threads share the equal amount of work as there are no any remainder operations now Suppose we have a 4x4 Matrix and 3 threads then each thread can't do the same work, In this case, extra work is done by the first thread. This is handled by the follwoing statement.


if (thread_number == 0) {
    // First thread does more job
    start_op = n_operations * thread_number;
    end_op = (n_operations * (thread_number + 1)) + rest_operations;
  }
  else {
    start_op = n_operations * thread_number + rest_operations;
    end_op = (n_operations * (thread_number + 1)) + rest_operations;
  }

 for example:

Thread 0:
start_op = 3 * 0 = 0
end_op = 3 * (0 + 1) = 3;
Thread 1:
start_op = 3 * 1 = 3
end_op = 3 * (1 + 1) = 6;
Thread 2:
start_op = 3 * 2 = 6
end_op = 3 * (2 + 1) = 9;


Now the multiplication is being done in the following way:

for (int op = start_op; op < end_op; ++op) {
    const int row = op % MATRIX_SIZE;
    const int col = op / MATRIX_SIZE;
    double r =0;
    for (int i = 0; i < MATRIX_SIZE; ++i) {
       double e1;
      double e2 = m2(i,col);
      
      if (row <= i)
      e1 = m1.symmatrix[(row * length - (row - 1) * row / 2 + i - row)];//symmat(i,j)
      else
      e1 = m1.symmatrix[(i * length - (i - 1) * i / 2 + row - i)];
      r += e1 * e2;
    }

And then saved to the result matrix 
 result(row,col) = r;








